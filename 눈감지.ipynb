{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd4c38f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4582fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (34, 26)#이미지 사이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7314c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()#기본으로 제공되는 얼굴인식모델\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')#얼굴 랜드마크(68개지점 탐지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b633cce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 26, 34, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 34, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 17, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               786944    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('models/eyemodel.h5')# 과거 학습시킨모델\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19798db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_eye(img, eye_points):#눈의 위치 찾음\n",
    "    x1, y1 = np.amin(eye_points, axis=0)\n",
    "    x2, y2 = np.amax(eye_points, axis=0)\n",
    "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2 #눈 중심\n",
    "\n",
    "    w = (x2 - x1) * 1.2\n",
    "    h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "    margin_x, margin_y = w / 2, h / 2 \n",
    "\n",
    "    min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "    max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "    eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)# int 타입으로 변환\n",
    "\n",
    "    eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]#눈 사각형 좌표\n",
    "\n",
    "    return eye_img, eye_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7136237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-4a4be158f0d5>:14: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)# int 타입으로 변환\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "cap = cv2.VideoCapture(0)\n",
    "prevTime = 0 #이전 시간\n",
    "Frame = 0\n",
    "times = 0\n",
    "perclos=0\n",
    "while cap.isOpened():\n",
    "    ret, img_ori = cap.read()\n",
    "    \n",
    "    curTime = time.time()#현재시간\n",
    "    sec = curTime - prevTime#프레임 한번 돌아온시간\n",
    "    prevTime = curTime #이전 시간을 현재시간으로 다시 저장시킴\n",
    "    fps = 1/(sec)#프레임 계산\n",
    "#     print (\"Time {0} \".format(sec))#한프레임 읽는데 걸린시간\n",
    "#     print (\"Estimated fps {0} \".format(fps))#1초동안 읽어들인 프레임수\n",
    "    Frame += fps#Frame=현재 까지 읽어들인 프레임수\n",
    "    #print(\"프레임수 %f\"%Frame)\n",
    "    str = \"FPS : %0.1f\" % Frame\n",
    "    cv2.putText(img_ori, str, (0, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0),2)\n",
    "    \n",
    "    if not ret: #읽어들여진 파일이 없다면 브레이크\n",
    "        break\n",
    "        \n",
    "    img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5) #사이즈 조정\n",
    "\n",
    "    img = img_ori.copy() #img copy해서 사용\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #img를 gray로\n",
    "\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        shapes = predictor(gray, face)\n",
    "        shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "        eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])#68개중 왼쪽눈\n",
    "        eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])#68개중 오른쪽눈\n",
    "\n",
    "        eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "        eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "        eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "        cv2.imshow('l', eye_img_l)#왼쪽눈에 l\n",
    "        cv2.imshow('r', eye_img_r)\n",
    "\n",
    "        eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255. #정도 파악\n",
    "        eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255. #정도파악\n",
    "\n",
    "        pred_l = model.predict(eye_input_l)#과거 학습시킨 왼쪽눈 상태\n",
    "        pred_r = model.predict(eye_input_r)\n",
    "\n",
    "        # visualize\n",
    "        state_l = '%.1f' if pred_l > 0.1 else '-' #영상에서 측정하는 왼쪽눈 상태\n",
    "        state_r = '%.1f' if pred_r > 0.1 else '-'#오른쪽 눈상태\n",
    "\n",
    "        state_l = state_l % pred_l\n",
    "        state_r = state_r % pred_r\n",
    "      \n",
    "       #perclos\n",
    "        if state_l == '-' and  state_r=='-':\n",
    "            eye_time =time.time()\n",
    "           \n",
    "            sec1 = eye_time - curTime\n",
    "            curTime = eye_time\n",
    "            if sec1 == 0:\n",
    "                pass\n",
    "            else:\n",
    "                fps1 = 1/(sec1)\n",
    "            \n",
    "            \n",
    "            times += fps1\n",
    "#             print(\"close time  %0.1f \"% times)\n",
    "\n",
    "        \n",
    "        \n",
    "        perclos=times/Frame\n",
    "        cv2.putText(img,\"Perclos:%.1f\"%perclos, (0, 75), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0),2)\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)#경계 사각형\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "        cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "        cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "        if perclos>=0.3:\n",
    "             cv2.putText(img, \"Wake up!!\",(100,200), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",# wake up 경고메세지 띄우기
    "        \n",
    "\n",
    "    cv2.imshow('result', img)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54945e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1171120f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
